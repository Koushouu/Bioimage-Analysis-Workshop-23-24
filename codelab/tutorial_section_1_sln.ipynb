{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis with Python - <font color='green'>Tutorial Pipeline Section 1</font>\n",
    "\n",
    "*originally created by Jonas Hartmann (Gilmour group, EMBL Heidelberg) in 2018*<br>\n",
    "*updated and modified in 2022 by Cheng-Yu Huang*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Table of Contents\n",
    "\n",
    "1. [About this Tutorial](#about)\n",
    "2. [Importing Modules & Packages](#import)\n",
    "3. [Loading & Handling Image Data](#load)\n",
    "4. [Preprocessing](#prepro)\n",
    "5. [Manual Thresholding & Threshold Detection](#thresh)\n",
    "6. [Adaptive Thresholding](#adaptive)\n",
    "7. [Improving Masks with Binary Morphology](#morpho)\n",
    "8. [Connected Components Labeling](#label)\n",
    "9. [Cell Segmentation by Seeding & Expansion](#seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  About this Tutorial <a id=about></a>\n",
    "\n",
    "*This tutorial aims to teach the basics of (bio-)image processing with python, in particular the analysis of fluorescence microscopy data. The tutorial is self-explanatory and follows a \"learning by doing\" philosophy. It consists of step by step instructions that guide students through the construction of a 2D single-cell segmentation pipeline.*\n",
    "\n",
    "#### Background \n",
    "\n",
    "The aim is to construct a pipeline for the identification and segmentation of cells in 2D confocal fluorescence microscopy images of a tissue with labeled membranes. This is among the most common tasks in bio-image analysis and is often essential for the extraction of useful quantitative information from microscopy data.\n",
    "\n",
    "The pipeline is constructed based on provided example images (see `example_data` directory), which are single-color spinning-disk confocal micrographs (objective: `40X 1.2NA W`) of cells in live zebrafish embryos in early development (~10h post fertilization), fluorescently labeled with a membrane-localized fusion protein (`mNeonGreen:Ggamma9`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Everything ready? Yes? Then let's get started!*\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing Modules & Packages <a id=import></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the package NumPy, which enables the manipulation of numerical arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<font color=red>Important note:</font> If you are not at all familiar with ```import```, arrays and NumPy, we strongly recommend that you first complete an introductory tutorial on this topic before carrying on!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that, once imported, we can use functions/modules from the package, for example to create an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'>Exercise</font>\n",
    "\n",
    "Using the import command as above, import two additional modules that we will be using frequently in this pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The image processing module scipy.ndimage as ndi\n",
    "### YOUR CODE HERE!\n",
    "import scipy.ndimage as ndi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading & Handling Image Data <a id=load></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'>Exercise</font>\n",
    "\n",
    "We will now proceed to load one of the example images and verify that we get what we expect. Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (i) Specify the file path\n",
    "# Create a string variable \"filepath\" with the path to the file you'd like to load (here: 'example_data\\example_cells_1.tif').\n",
    "### YOUR CODE HERE!\n",
    "filepath = r'example_data\\example_cells_1.tif' # This is a relative path\n",
    "\n",
    "# Note: Paths and filenames can contain slashes, empty spaces and other special symbols, which can cause \n",
    "#       trouble for programming languages under certain circumstances. To circumvent such trouble, add \n",
    "#       the letter r before your string definition to create a so-called 'raw string', which is not\n",
    "#       affected by these problems (e.g. my_raw_string = r\"some string with funny symbols: \\\\\\!/~***!\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (ii) Load the image\n",
    "\n",
    "# Import the function 'imread' from the module 'skimage.io'.\n",
    "### YOUR CODE HERE!\n",
    "from skimage.io import imread\n",
    "\n",
    "# Load 'example_cells_1.tif' and store it in a variable.\n",
    "# Suggested name for the variable: img\n",
    "### YOUR CODE HERE!\n",
    "img = imread(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (iii) Check variable type, file shape and data type\n",
    "\n",
    "# Print that 'img' is a variable of type 'ndarray' - use Python's built-in function 'type'.\n",
    "### YOUR CODE HERE!\n",
    "print(\"Loaded array is of type:\", type(img))\n",
    "\n",
    "# Print the shape of the array by looking at its 'shape' attribute. \n",
    "# Make sure you understand the output!\n",
    "### YOUR CODE HERE!\n",
    "print(\"Loaded array has shape:\", img.shape)\n",
    "\n",
    "# Print the datatype of the individual numbers in the array. You can use the array attribute 'dtype' to do so.\n",
    "# Make sure you understand the output!\n",
    "### YOUR CODE HERE!\n",
    "print(\"Loaded values are of type:\", img.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The dtype should be 'uint8', because these are unsigned 8-bit integer images.\n",
    "\n",
    "This means that the intensity values range from 0 to 255 in steps of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (iv) Image visulization with matplotlib\n",
    "# This is the most classic/ original way in python to show image\n",
    "\n",
    "# First import plotting module matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use plt.imshow to display the image. plt.imshow has parameters that can be specified, such as:\n",
    "#  * colormap (cmap): for common bioimage analysis purpose you will set it to 'gray'. There are other options, such as 'viridis' and 'autumn' or 'winter'\n",
    "#  * interpolation: for scientific purpose we don't want any interpolation, so set it to 'none'. The default setting is 'antialiased'\n",
    "plt.imshow(img, interpolation='none', cmap='gray')\n",
    "\n",
    "# P.S. You can have plt.figure() before plt.imshow() to define the figure size. For example:\n",
    "# plt.figure(figsize=(7,7))\n",
    "# plt.imshow(img, interpolation='none', cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocessing <a id=prepro></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "The goal of image preprocessing is to prepare or optimize the images to make further analysis easier. Usually, this boils down to increasing the signal-to-noise ratio by removing noise and background and by enhancing structures of interest. The specific preprocessing steps used in a pipeline depend on the type of sample, the microscopy technique used, the image quality, and the desired downstream analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Smoothing\n",
    "\n",
    "A Gaussian filter smoothens an image by convolving it with a Gaussian-shaped kernel. In the case of a 2D image, the Gaussian kernel is also 2D and will look something like this:\n",
    "\n",
    "<img src=\"ipynb_images\\gaussian_kernel_grid.png\" alt=\"Gaussian Kernel Figure\" style=\"width: 150px;\"/>\n",
    "\n",
    "How much the image is smoothed by a Gaussian kernel is determined by the standard deviation  of the Gaussian distribution, usually referred to as **sigma** ($\\sigma$). A higher $\\sigma$ means a broader distribution and thus more smoothing.\n",
    "\n",
    "**How to choose the correct value of $\\sigma$?**\n",
    "\n",
    "This depends a lot on your images, in particular on the pixel size. In general, the chosen $\\sigma$ should be large enough to blur out noise but small enough so the \"structures of interest\" do not get blurred too much. Usually, the best value for $\\sigma$ is simply found by trying out some different options and looking at the result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'>Exercise</font>\n",
    "\n",
    "Perform Gaussian smoothing and visualize the result.\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Import the image processing module scipy.ndimage as ndi\n",
    "\n",
    "import scipy.ndimage as ndi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (ii) Create a variable for the smoothing factor sigma, which should be an integer value\n",
    "\n",
    "sigma = 3\n",
    "# After implementing the Gaussian smoothing function below, you can modify this variable \n",
    "# to find the ideal value of sigma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (iii) Perform the smoothing on the image\n",
    "\n",
    "# To do so, use the Gaussian filter function 'ndi.gaussian_filter' from the \n",
    "# image processing module 'scipy.ndimage'. Check out the documentation of scipy to see how to use this function. \n",
    "# Allocate the output to a new variable 'img_smooth'\n",
    "img_smooth = ndi.gaussian_filter(img, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (iv) Visualize the result\n",
    "plt.imshow(img_smooth, interpolation='none', cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Manual Thresholding & Threshold Detection <a id=thresh></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "The easiest way to distinguish foreground objects (here: membranes) from the image background is to threshold the image, meaning all pixels with an intensity above a certain threshold are accepted as foreground, all others are set as background.\n",
    "\n",
    "To find the best threshold for a given image, one option is to simply try out different thresholds manually. Alternatively, one of many algorithms for automated **'threshold detection'** can be used. These algorithms use information about the image (such as the histogram) to automatically find a suitable threshold value, often under the assumption that the background and foreground pixels in an image belong to two clearly distinct populations in terms of their intensity. \n",
    "\n",
    "There are many different algorithms for threshold detection and it is often hard to predict which one will produce the nicest and most robust result for a particular dataset. It therefore makes sense to try out a bunch of different options.\n",
    "\n",
    "For this pipeline, we will ultimately use a more advanced thresholding approach, which also accounts (to some extent) for variations in signal across the field of view: adaptive thresholding. \n",
    "\n",
    "But first, let's experiment a bit with threshold detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'>Exercise</font>\n",
    "\n",
    "Try out manual thresholding and automated threshold detection.\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (i) Create a variable for a manually set threshold, which should be an integer\n",
    "\n",
    "# This can be changed later to find a suitable value.\n",
    "thresh = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (ii) Perform thresholding on the smoothed image\n",
    "\n",
    "# Remember that you can use relational (Boolean) expressions such as 'smaller' (<), 'equal' (==)\n",
    "# or 'greater or equal' (>=) with numpy arrays - and you can directly assign the result to a new\n",
    "# variable.\n",
    "mem = img_smooth > thresh\n",
    "\n",
    "# Check the dtype of your thresholded image\n",
    "# You should see that the dtype is 'np.bool', which stands for 'Boolean' and means the array\n",
    "# is now simply filled with 'True' and 'False', where 'True' is the foreground (the regions\n",
    "# above the threshold) and 'False' is the background.\n",
    "print(mem.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (iii) Visualize the result\n",
    "\n",
    "plt.imshow(mem, interpolation='none', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (iv) Try out different thresholds to find the best one\n",
    "\n",
    "# If you are using jupyter notebook, you can adapt the code below to\n",
    "# interactively change the threshold and look for the best one. These\n",
    "# kinds of interactive functions are called 'widgets' and are very \n",
    "# useful in exploratory data analysis to create greatly simplified\n",
    "# 'User Interfaces' (UIs) on the fly.\n",
    "# As a BONUS exercise, try to understand or look up how the widget works\n",
    "# and play around with it a bit!\n",
    "# (Note: If this just displays a static image without a slider to adjust\n",
    "#        the threshold or if it displays a text warning about activating\n",
    "#        the 'widgetsnbextension', check out the note below!)\n",
    "\n",
    "# Prepare widget\n",
    "from ipywidgets import interact\n",
    "@interact(thresh=(10,250,10))\n",
    "def select_threshold(thresh=100):\n",
    "    \n",
    "    # Thresholding\n",
    "    ### ADAPT THIS: Change 'img_smooth' into the variable you stored the smoothed image in!\n",
    "    mem = img_smooth > thresh\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.imshow(mem, interpolation='none', cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (v) Perfom automated threshold detection with Otsu's method\n",
    "\n",
    "# The scikit-image module 'skimage.filters.thresholding' provides\n",
    "# several threshold detection algorithms. The most popular one \n",
    "# among them is Otsu's method. Using what you've learned so far,\n",
    "# import the 'threshold_otsu' function, use it to automatically \n",
    "# determine a threshold for the smoothed image, apply the threshold,\n",
    "# and visualize the result.\n",
    "### YOUR CODE HERE!\n",
    "# Import\n",
    "from skimage.filters.thresholding import threshold_otsu\n",
    "\n",
    "# Calculate and apply threshold\n",
    "thresh = threshold_otsu(img_smooth)\n",
    "mem = img_smooth > thresh\n",
    "    \n",
    "# Visualization\n",
    "plt.imshow(mem, interpolation='none', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (vi) BONUS: Did you notice the 'try_all_threshold' function?\n",
    "\n",
    "# That's convenient! Use it to automatically test the threshold detection\n",
    "# functions in 'skimage.filters.thresholding'. Don't forget to adjust the\n",
    "# 'figsize' parameter so the resulting images are clearly visible.\n",
    "### YOUR CODE HERE!\n",
    "from skimage.filters.thresholding import try_all_threshold\n",
    "fig = try_all_threshold(img_smooth, figsize=(10,10), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Adaptive Thresholding <a id=adaptive></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "Simply applying a fixed intensity threshold does not always produce a foreground mask of sufficiently high quality, since background and foreground intensities often vary across the image. In our example image, for instance, the intensity drops at the image boundaries - a problem that cannot be resolved just by changing the threshold value.\n",
    "\n",
    "One way of addressing this issue is to use an *adaptive thresholding* algorithm, which adjusts the threshold locally in different regions of the image to account for varying intensities.\n",
    "\n",
    "Although `scikit-image` provides a function for adaptive thresholding (called `threshold_local`), we will here implement our own version, which is slightly different and will hopefully make the concept of adaptive thresholding very clear.\n",
    "\n",
    "Our approach to adaptive tresholding works in two steps:\n",
    "\n",
    "1. Generation of a \"background image\"\n",
    "\n",
    " This image should - across the entire image - always have higher intensities than the local background but lower intensities than the local foreground. This can be achieved by strong blurring/smoothing of the image, as illustrated in this 1D example:\n",
    "\n",
    " <img src=\"ipynb_images\\adaptive_bg_1D.png\" alt=\"Adaptive Background Figure\" style=\"width: 400px;\"/><br>\n",
    "    \n",
    "2. Thresholding of the original image with the background\n",
    "\n",
    " Instead of thresholding with a single value, every pixel in the image is thresholded with the corresponding pixel of the \"background image\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'> Exercise </font>\n",
    "\n",
    "Implement the two steps of the adaptive background subtraction:\n",
    "\n",
    "1. Use a strong \"mean filter\" (aka \"uniform filter\") to create the background image. This simply assigns each pixel the average value of its local neighborhood. Just like the Gaussian blur, this can be done by convolution, but this time using a \"uniform kernel\" like this one:\n",
    "\n",
    " <img src=\"ipynb_images\\uniform_filter_SE.png\" alt=\"Uniform Filter SE Figure\" style=\"width: 300px;\"/>\n",
    "    \n",
    " To define which pixels should be considered as the local neighborhood of a given pixel, a `structuring element` (`SE`) is    used. This is a small binary image where all pixels set to `1` will be considered as part of the neighborhood and all pixels set to `0` will not be considered. Here, we use a disc-shaped `SE`, as this reduces artifacts compared to a square `SE`.\n",
    "  \n",
    " *Side note:* A strong Gaussian blur would also work to create the background mask. For the Gaussian blur, the analogy to the `SE` is the `sigma` value, which in a way also determines the size of the local neighborhood.<br><br>\n",
    "\n",
    "2. Use the background image for thresholding. In practical terms, this works in exactly the same way as thresholding with a single value, since numpy arrays will automatically perform element-wise (pixel-by-pixel) comparisons when compared to other arrays of the same shape by a relational (Boolean) expression.\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1\n",
    "# ------\n",
    "\n",
    "# (i) Create a disk-shaped structuring element (SE) and asign it to a new variable.\n",
    "\n",
    "# Import module disk from skimage.morphology\n",
    "from skimage.morphology import disk\n",
    "\n",
    "# Create SE for mean filtering\n",
    "# Set radius r for the disk\n",
    "r = 15\n",
    "# create disk, save it as SE\n",
    "footprint = disk(r)\n",
    "\n",
    "# Visualize the SE\n",
    "plt.imshow(footprint, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (ii) Create the background, and visulize\n",
    "\n",
    "# Run a mean filter over the image using the disc SE and assign the output to a new variable.\n",
    "# Use the function 'skimage.filters.rank.mean'.\n",
    "from skimage.filters import rank \n",
    "\n",
    "background = rank.mean(img_smooth, footprint=footprint)\n",
    "\n",
    "plt.imshow(background, interpolation='none', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "# ------\n",
    "\n",
    "# (iii) Threshold the Gaussian-smoothed original image (img_smooth) against the background image created in step 1 \n",
    "#      using a relational expression\n",
    "\n",
    "mem = img_smooth > background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (v) Visualize and understand the output. \n",
    "\n",
    "plt.imshow(mem, interpolation='none', cmap='gray')\n",
    "\n",
    "# What do you observe? \n",
    "# Are you happy with this result as a membrane segmentation? \n",
    "# Adapt the size of the circular SE to optimize the result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Improving Masks with Binary Morphology <a id=morpho></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "Morphological operations such as `erosion`, `dilation`, `closing` and `opening` are common tools used to improve masks after they are generated by thresholding. They can be used to fill small holes, remove noise, increase or decrease the size of an object, or smoothen mask outlines.\n",
    "\n",
    "Most morphological operations are once again simple kernel functions that are applied at each pixel of the image based on their neighborhood as defined by a `structuring element` (`SE`). For example, `dilation` simply assigns to the central pixel the maximum pixel value within the neighborhood; it is a maximum filter. Conversely, `erosion` is a minimum filter. Additional options emerge from combining the two: `morphological closing`, for example, is a `dilation` followed by an `erosion`. This is used to fill in gaps and holes or smoothing mask outlines without significantly changing the mask's area. Finally, there are also some more complicated morphological operations, such as `hole filling`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'>Exercise</font>\n",
    "\n",
    "Improve the membrane segmentation from above with morphological operations.\n",
    "\n",
    "Specifically, use `binary hole filling` to get rid of the speckles of foreground pixels that litter the insides of the cells. Furthermore, try different other types of morphological filtering to see how they change the image and to see if you can improve the membrane mask even more, e.g. by filling in gaps.\n",
    "\n",
    "Follow the instructions in the comments below. Visualize all intermediate results of your work and remember to \"zoom in\" to get a closer look by slicing out and then plotting a subsection of the image array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (i) Get rid of speckles using binary hole filling\n",
    "\n",
    "# Use the function 'ndi.binary_fill_holes' for this. Be sure to check the docs to\n",
    "# understand exactly what it does. For this to work as intended, you will have to \n",
    "# invert the mask, which you can do using the function `np.logical_not` or the\n",
    "# corresponding operator '~'. Again, be sure to understand why this has to be done\n",
    "# and don't forget to revert the result back.\n",
    "\n",
    "mem_holefilled = ~ndi.binary_fill_holes(~mem)\n",
    "plt.imshow(mem_holefilled, interpolation='none', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) Closing the gaps in the membrane by dilation\n",
    "\n",
    "# Create a SE for the binary operation with disk()\n",
    "r = 7\n",
    "SE = disk(r)\n",
    "\n",
    "# Perform dilation with the python function ndi.binary_dilation\n",
    "mem_dilated = ndi.binary_dilation(mem_holefilled, structure=SE)\n",
    "\n",
    "# Now visulize the result\n",
    "plt.imshow(mem_dilated, cmap = 'gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (iii) Restore the membrane shape by erosion\n",
    "\n",
    "# Using the same SE as before, perform erosion with ndi.binary_erosion\n",
    "mem_eroded = ndi.binary_erosion(mem_dilated, structure=SE)\n",
    "\n",
    "# Now visulize the result\n",
    "plt.imshow(mem_eroded, cmap = 'gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (iv) [BONUS 1] If you pay close attention, you will notice that some of these operations introduce \n",
    "# artefacts at the image boundaries. Can you come up with a way of solving this? (Hint: 'np.pad')\n",
    "# [BONUS 2] You just did dilation and erosion with the same SE. These two operations\n",
    "# combined together is called \"closing\". Try ndi.binary_closing to do the same thing in one line\n",
    "\n",
    "r = 7\n",
    "SE = disk(r)\n",
    "pad_size = r + 1\n",
    "mem_padded = np.pad(mem_holefilled, pad_size, mode='reflect')\n",
    "mem_final = ndi.binary_closing(mem_padded, structure=SE)\n",
    "mem_final = mem_final[pad_size:-pad_size, pad_size:-pad_size]\n",
    "plt.imshow(mem_final, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (iii) Visualize the final result\n",
    "\n",
    "plt.imshow(mem_final, interpolation='none', cmap='gray')\n",
    "\n",
    "# At this point you should have a pretty neat membrane mask.\n",
    "# If you are not satisfied with the quality your membrane segmentation, you should go back \n",
    "# and fine-tune the size of the SE in the adaptive thresholding section and also optimize\n",
    "# the morphological cleaning operations.\n",
    "# Note that the quality of the membrane segmentation will have a significant impact on the \n",
    "# cell segmentation we will perform next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Connected Components Labeling <a id=label></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "Based on the membrane segmentation, we can get a preliminary segmentation of the cells in the image by considering each background region surrounded by membranes as a cell. This can already be good enough for many simple measurements.\n",
    "\n",
    "The only thing we still need to do in order to get there is to label each cell individually. Only if each separate cell has a unique number (an `ID`) assigned, values such as the mean intensity can be measured and analyzed at the single-cell level.\n",
    "\n",
    "The approach used to achieve this is called `connected components labeling`. It gives every connected group of foreground pixels a unique `ID` number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'>Exercise</font>\n",
    "\n",
    "Use your membrane segmentation for connected components labeling.\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (i) Label connected components\n",
    "\n",
    "# Use the function 'ndi.label' from the 'ndimage' module. \n",
    "# Note that this function labels foreground pixels (1s, not 0s), so you may need \n",
    "# to invert your membrane mask just as for hole filling above.\n",
    "# Also, note that 'ndi.label' returns another result in addition to the labeled \n",
    "# image. Read up on this in the function's documention and make sure you don't\n",
    "# mix up the two outputs!\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "cell_labels, _ = ndi.label(~mem_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (ii) Visualize the output\n",
    "\n",
    "# Here, it is no longer ideal to use a 'gray' colormap, since we want to visualize that each\n",
    "# cell has a unique ID. Play around with different colormaps (check the docs to see what\n",
    "# types of colormaps are available) and choose one that you are happy with.\n",
    "\n",
    "plt.imshow(cell_labels, interpolation='none', cmap='inferno')\n",
    "\n",
    "# Take a close look at the picture and note mistakes in the segmentation. Depending on the\n",
    "# quality of your membrane mask, there will most likely be some cells that are 'fused', meaning \n",
    "# two or more cells are labeled as the same cell; this is called \"under-segmentation\". \n",
    "# We will resolve this issue in the next step. Note that our downstream pipeline does not involve \n",
    "# any steps to resolve \"over-segmentation\" (i.e. a cell being wrongly split into multiple labeled\n",
    "# areas), so you should tune your membrane mask such that this is not a common problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cell Segmentation by Seeding & Expansion <a id=seg></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "The segmentation we achieved by membrane masking and connected components labeling is a good start. We could for example use it to measure the fluorescence intensity in each cell's cytoplasm. However, we cannot use it to measure intensities at the membrane of the cells, nor can we use it to accurately measure features like cell shape or size.\n",
    "\n",
    "To improve this (and to resolve cases of under-segmentation), we can use a \"seeding & expansion\" strategy. Expansion algorithms such as the `watershed` start from a small `seed` and \"grow outward\" until they touch the boundaries of neighboring cells, which are themselves growing outward from neighboring seeds. Since the \"growth rate\" at the edge of the growing areas is dependent on image intensity (higher intensity means slower expansion), these expansion methods end up tracing the cells' outlines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeding by Distance Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "A `seed image` contains a few pixels at the center of each cell labeled by a unique `ID` number and surrounded by zeros. The expansion algorithm will start from these central pixels and grow outward until all zeros are overwritten by an `ID` label. In the case of `watershed` expansion, one can imagine the `seeds` as the sources from which water pours into the cells and starts filling them up.\n",
    "\n",
    "For multi-channel images that contain a nuclear label, it is common practice to mask the nuclei by thresholding and use an eroded version of the nuclei as seeds for cell segmentation. However, there are good alternative seeding approaches for cases where nuclei are not available or not nicely separable by thresholding.\n",
    "\n",
    "Here, we will use a `distance transform` for seeding. In a `distance transform`, each pixel in the foreground (here the cells) is assigned a value corresponding to its distance from the closest background pixel (here the membrane segmentation). In other words, we encode within the image how far each pixel of a cell is away from the membrane (see figure below). The pixels furthest away from the membrane will be at the center of the cells and will have the highest values. Using a function to detect `local maxima`, we will find these high-value peaks and use them as seeds for our segmentation.\n",
    "\n",
    "<img src=\"ipynb_images\\distance_transform.png\" alt=\"Distance Transform Figure\" style=\"width: 900px;\"/>\n",
    "\n",
    "One big advantage of this approach is that it will create two separate seeds even if two cells are connected by a hole in the membrane segmentation. Thus, under-segmentation artifacts will be reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'> Exercise </font>\n",
    "\n",
    "Find seeds using the distance transform approach.\n",
    "\n",
    "This involves the following three steps:\n",
    "\n",
    "1. Run the distance transform on your membrane mask.\n",
    "\n",
    "2. Due to irregularities in the membrane shape, the distance transform may have some smaller local maxima in addition to those at the center of the cells. This will lead to additional seeds, which will lead to over-segmentation. To resolve this problem, smoothen the distance transform using Gaussian smoothing. \n",
    "\n",
    "3. Find the seeds by detecting local maxima. Optimize the seeding by changing the amount of smoothing done in step 2, aiming to have exactly one seed for each cell (although this may not be perfectly achievable).\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (i) Run a distance transform on the membrane mask\n",
    "\n",
    "# Use the function 'ndi.distance_transform_edt'.\n",
    "# You may need to invert your membrane mask so the distances are computed on\n",
    "# the cells, not on the membranes.\n",
    "dist_trans = ndi.distance_transform_edt(~mem_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (ii) Visualize the output and understand what you are seeing.\n",
    "\n",
    "plt.imshow(dist_trans, interpolation='none', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (iii) Smoothen the distance transform\n",
    "\n",
    "# Use 'scipy.ndimage.gaussian_filter' to do so.\n",
    "# You will have to optimize your choice of 'sigma' based on the outcome below.\n",
    "\n",
    "# Applying the filter\n",
    "dist_trans_smooth = ndi.gaussian_filter(dist_trans, sigma=5)\n",
    "\n",
    "# Visualizing\n",
    "plt.imshow(dist_trans_smooth, interpolation='none', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (iv) Get the local maxima (the 'peaks') from the distance transform\n",
    "\n",
    "# Use the function 'peak_local_max' from the module 'skimage.feature'. This function will return the\n",
    "# indices/ coordinates of the pixels where the local maxima are. \n",
    "\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "seeds = peak_local_max(dist_trans_smooth, min_distance=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (v) However, we instead need a boolean mask of the same shape as the original image, where all \n",
    "# the local maximum pixels are labeled as `1` and everything else as `0`.\n",
    "\n",
    "# Let's do it step by step. First try have a look at what is in seeds. Can you get these values?\n",
    "# Number of seeds\n",
    "print(f'There are {np.shape(seeds)[0]} seeds')\n",
    "# The X coordinate of the first seed\n",
    "print(seeds[0][0])\n",
    "# The Y coordinate of the 13th seed\n",
    "print(seeds[13][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we will start by creating a boolean matrix/ image same size as the original image, but with\n",
    "# all pixel values as 0/ false\n",
    "seeds_mask = np.zeros_like(dist_trans_smooth, dtype = bool)\n",
    "\n",
    "# For loop through all entries in seeds\n",
    "for seed_id in range(np.shape(seeds)[0]):\n",
    "    seeds_mask[seeds[seed_id][0],seeds[seed_id][1]] = 1\n",
    "\n",
    "# P.S. for advanced Python coder - this also works without a for loop:\n",
    "# seeds_mask[tuple(seeds.T)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (vi) Visualize the output \n",
    "\n",
    "# Dilate the seeds for visulization\n",
    "seeds_dil = ndi.binary_dilation(seeds_mask, structure=disk(7))\n",
    "\n",
    "# Visualize\n",
    "\n",
    "seeds_dil_mask = np.ma.array(seeds_dil, mask=seeds_dil==0)\n",
    "plt.imshow(cell_labels, interpolation='none', cmap='inferno')\n",
    "plt.imshow(seeds_dil_mask, interpolation='none', cmap='prism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (vii) Label the seeds\n",
    "seeds_labeled = ndi.label(seeds_dil)[0]\n",
    "\n",
    "# Visualize\n",
    "seeds_labeled_mask = np.ma.array(seeds_labeled, mask=seeds_labeled==0)\n",
    "plt.imshow(cell_labels, interpolation='none', cmap='gray')\n",
    "plt.imshow(seeds_labeled_mask, interpolation='none', cmap='prism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (viii) Optimize the seeding\n",
    "\n",
    "# Ideally, there should be exactly one seed for each cell.\n",
    "# If you are not satisfied with your seeding, go back to the smoothing step above and optimize 'sigma'\n",
    "# to get rid of additional maxima. You can also try using the keyword argument 'min_distance' in \n",
    "# 'peak_local_max' to solve cases where there are multiple small seeds at the center of a cell. Note \n",
    "# that good seeding is essential for a good segmentation with an expansion algorithm. However, no \n",
    "# segmentation is perfect, so it's okay if a few cells end up being oversegmented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expansion by Watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "To achieve a cell segmentation, the `seeds` now need to be expanded outward until they follow the outline of the cell. The most commonly used expansion algorithm is the `watershed`.\n",
    "\n",
    "Imagine the intensity in the raw/smoothed image as a topographical height profile; high-intensity regions are peaks, low-intensity regions are valleys. In this representation, cells are deep valleys (with the seeds at the center), enclosed by mountains. As the name suggests, the `watershed` algorithm can be understood as the gradual filling of this landscape with water, starting from the seed. As the water level rises, the seed expands - until it finally reaches the 'crest' of the cell membrane 'mountain range'. Here, the water would flow over into the neighboring valley, but since that valley is itself filled up with water from the neighboring cell's seed, the two water surfaces touch and the expansion stops.\n",
    "\n",
    "<img src=\"ipynb_images\\watershed_illustration.png\" alt=\"Watershed Figure\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'>Exercise</font>\n",
    "\n",
    "Expand your seeds by means of a watershed expansion.\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (i) Perform watershed\n",
    "\n",
    "# Use the function 'watershed' from the module 'skimage.segmentation'.\n",
    "# Use the labeled cell seeds and the smoothed membrane image as input.\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "ws = watershed(img_smooth, seeds_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (ii) Visulize\n",
    "plt.imshow(img, interpolation='none', cmap='gray')\n",
    "plt.imshow(ws, interpolation='none', cmap='prism', alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (v) Image visulization with napari: \n",
    "# This is the relatively new way in python to show image. In this workshop we will use napari for visulization\n",
    "\n",
    "# First import module napari\n",
    "import napari\n",
    "\n",
    "# Create an empty viewer object\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Use viewer.add_image() and pass the image as a variable to visulize the image. Similar to that for matplotlib, set options:\n",
    "#  * colormap as 'gray'\n",
    "#  * interpolation (interpolation2d) is 'nearest' (which correspond to minimum interpolation) by default, so no need to specify \n",
    "#  * name as 'Raw Image'\n",
    "viewer.add_image(img, colormap = 'gray', name= 'Raw Image')\n",
    "\n",
    "# Don't close the Napari window - from now on we will add our intermediate results to the napari window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the ws results as labels\n",
    "viewer.add_labels(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *A Note on Segmentation Quality*\n",
    "\n",
    "This concludes the segmentation of the cells in the example image. Depending on the quality you achieved in each step along the way, the final segmentation may be of greater or lesser quality (in terms of over-/under-segmentation errors).\n",
    "\n",
    "It should be noted that the segmentation will likely *never* be perfect, as there is usually a trade-off between over- and undersegmentation.\n",
    "\n",
    "This raises an important question: ***When should I stop trying to optimize my segmentation?***\n",
    "\n",
    "There is no absolute answer to this question but the best answer is probably this: ***When you can use it to address your biological questions!***\n",
    "\n",
    "*Importantly, this implies that you should already have relatively clear questions in mind when you are working on the segmentation!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iii) Write (and Save) your segmentation result as tif file\n",
    "\n",
    "# Use the function 'imsave' from the 'skimage.io' module. Make sure that the array you are \n",
    "# writing is of integer type. If necessary, you can use the method 'astype' for conversions, \n",
    "# e.g. 'some_array.astype(np.uint8)' or 'some_array.astype(np.uint16)'. Careful when \n",
    "# converting a segmentation to uint8; if there are more than 255 cells, the 8bit format\n",
    "# doesn't have sufficient bit-depth to represent all cell IDs!\n",
    "#\n",
    "# You can also try adding the segmentation to the original image, creating an image with\n",
    "# two channels, one of them being the segmentation. \n",
    "#\n",
    "# After writing the file, load it into Fiji and check that everything worked as intended.\n",
    "### YOUR CODE HERE!\n",
    "from skimage.io import imsave\n",
    "imsave(\"example_cells_1_seg.tif\", ws.astype(np.uint16))\n",
    "\n",
    "# P.S. You can also save the file as numpy.\n",
    "# Numpy files allow fast storage and reloading of numpy arrays. Use the function 'np.save'\n",
    "# to save the array and reload it using 'np.load'.\n",
    "\n",
    "# np.save(\"example_cells_1_seg\", clean_seg)  # Save\n",
    "# seg = np.load(\"example_cells_1_seg.npy\")  # Load\n",
    "# print(clean_seg.shape, seg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='teal'>*Congratulations! You have completed the tutorial!*</font>\n",
    "\n",
    "**We hope you enjoyed the ride and learned a lot!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
