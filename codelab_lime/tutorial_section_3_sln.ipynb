{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis with Python - <font color='teal'>Tutorial Pipeline Section 3</font>\n",
    "\n",
    "*originally created in 2016*<br>\n",
    "*updated and converted to a Jupyter notebook in 2017*<br>\n",
    "*updated and converted to python 3 in 2018*<br>\n",
    "*by Jonas Hartmann (Gilmour group, EMBL Heidelberg)*<br>\n",
    "*updated in 2022 by Cheng-Yu Huang*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\**BONUS\\** >> Batch Processing <a id=batch></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "In practice, we never work with just a single image, so we would like to make it possible to run our analysis pipeline for multiple images and then collect and analyze all the results. This final section of the tutorial shows how to do just that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'>Exercise</font>\n",
    "\n",
    "To run a pipeline multiple times, it needs to be packaged into a function or - even better - as a separate module. Jupyter notebook is not well suited for this, so if you're working in a notebook, first extract your code to a `.py` file (see instructions below). If you are not working in a notebook, create a copy of your pipeline; we will modify this copy into a function that can then be called repeatedly for different images.\n",
    "\n",
    "To export a jupyter notebook as a `.py` file, use `File > Download as > Python (.py)`, then save the file. Open the resulting python script in a text editor or in an IDE like PyCharm. \n",
    "\n",
    "\n",
    "#### Let's clean the script a bit:\n",
    "\n",
    "- Remove the line `%matplotlib [inline|notebook|qt]`. It is not valid python code outside of a Jupyter notebook.\n",
    "\n",
    "\n",
    "- Go through the script and comment out everything related to plotting; when running a pipeline for dozens or hundreds of images, we usually do not want to generate tons of plots. Similarly, it can make sense to remove some print statments if you have many of them.\n",
    "\n",
    "\n",
    "- Remove the sections `Manual Thresholding` and `Connected Components Labeling`; they are not used in the final segmentation.\n",
    "\n",
    "\n",
    "- Remove the sections `Simple Analysis and Visualization` and `Writing Output to Files`; we will collect the output for each image when running the pipeline in a loop. That way, everything can be analyzed at once at the end. \n",
    "    - Note that, even though we skip it here, it is often very useful to store every input file's corresponding outputs in new files. When doing so, the output files should use the name of the input file modified with an additional suffix. For example, the results extracted when analyzing `img_1.tif` might best be stored as `img_1_results.pkl`.\n",
    "    - You can implement this approach for saving the segmentations and/or the result dicts as a *bonus* exercise!\n",
    "\n",
    "\n",
    "- Feel free to delete some of the background information to make the script more concise.\n",
    "\n",
    "\n",
    "#### Converting the pipeline to a function:\n",
    "\n",
    "Convert the entire pipeline into a function that accepts a directory and a filename as input, runs everything, and returns the final segmentation and the results dictionary. To do this, you must:\n",
    "\n",
    "- Add the function definition statement at the beginning of the script (after the imports)\n",
    "- Replace the 'hard-coded' directory path and filename by variables that are accepted by the function\n",
    "- Indent all the code\n",
    "- Add a return statement at the end\n",
    "\n",
    "\n",
    "#### Importing the function and running it for multiple input files:\n",
    "\n",
    "To actually run the pipeline function for multiple input files, we need to do the following:\n",
    "\n",
    "- Import the pipeline function from the `.py` file\n",
    "- Iterate over all the filenames in a directory\n",
    "- For each filename, call the pipeline function\n",
    "- Collect the returned results\n",
    "\n",
    "Once you have converted your pipeline into a function as described above, you can import and run it according to the instructions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution Note\n",
    "\n",
    "The converted version of the pipeline can be found in `batch_processing_solution.py`. \n",
    "\n",
    "Note that the most of the exercise comments have been removed so it doesn't look too cluttered. However, this level of clean-up is probably a bit extreme; it is generally recommended to retain at least basic comments on the purpose of each code block. \n",
    "\n",
    "Also note that a doc string was added to the function definition (the string designated with three `\"\"\"` at the start and end, directly under the function definition). This is a very useful reference, since it is automatically recognized as a help message by Jupyter notebook (and other IDEs), so you can easily double-check what an imported function does, for example by typing `run_pipeline?` in a code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Test if your pipeline function actually works\n",
    "\n",
    "# Import your function using the normal python syntax for imports, like this:\n",
    "#   from your_module import your_function\n",
    "# Run the function and visualize the resulting segmentation. Make sure everything works as intended.\n",
    "\n",
    "from batch_processing_solution import run_pipeline\n",
    "pip_seg, pip_results = run_pipeline(r\"example_data\", r'example_cells_1.tif')\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(np.zeros_like(pip_seg), interpolation='none', cmap='gray', vmax=1)  # Simple black background\n",
    "plt.imshow(np.ma.array(pip_seg, mask=pip_seg==0), interpolation='none', cmap='prism')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (ii) Get all relevant filenames from the input directory\n",
    "\n",
    "# Use the function 'listdir' from the module 'os' to get a list of all the files\n",
    "# in a directory. Find a way to filter out only the relevant input files, namely\n",
    "# \"example_cells_1.tif\" and \"example_cells_2.tif\". Of course, one would usually\n",
    "# do this for many more images, otherwise it's not worth the effort.\n",
    "# Hint: Loop over the filenames and use if statements to decide which ones to \n",
    "#       keep and which ones to throw away.\n",
    "\n",
    "# Get all files\n",
    "dirpath = r\"example_data\"\n",
    "from os import listdir\n",
    "filelist = listdir(dirpath)\n",
    "\n",
    "# Filter for target files: simple option\n",
    "# Note that this will use ALL files with a .tif ending, which in some circumstances\n",
    "# may include files that are not supposed to be used!\n",
    "target_files = []\n",
    "for fname in filelist:\n",
    "    if fname.endswith('.tif'):\n",
    "        target_files.append(fname)\n",
    "print(target_files)\n",
    "\n",
    "# Filter for target files: advanced option using regex and a list comprehension\n",
    "import re\n",
    "target_pattern = re.compile(\"^example_cells_\\d+\\.tif$\")\n",
    "target_files = [fname for fname in filelist if target_pattern.match(fname)]\n",
    "print(target_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iii) Iterate over the input filenames and run the pipeline function\n",
    "\n",
    "# Be sure to collect the output of the pipeline function in a way that allows\n",
    "# you to trace it back to the file it came from. You could for example use a\n",
    "# dictionary with the filenames as keys.\n",
    "\n",
    "# Initialize empty dictionaries\n",
    "all_seg = {}\n",
    "all_results = {}\n",
    "\n",
    "# Iterate over files and run pipeline for each\n",
    "for fname in target_files:\n",
    "    pip_seg, pip_results = run_pipeline(dirpath, fname)\n",
    "    all_seg[fname] = pip_seg\n",
    "    all_results[fname] = pip_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iv) Recreate one of the scatterplots from above but this time with all the cells\n",
    "\n",
    "# You can color-code the dots to indicate which file they came from. Don't forget to\n",
    "# add a corresponding legend.\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "colors = ['blue','red']\n",
    "for key, color in zip(sorted(all_results.keys()), colors):\n",
    "    plt.scatter(all_results[key][\"cell_area\"], all_results[key][\"cell_edge\"],\n",
    "                edgecolor='k', c=color, s=30, alpha=0.5, label=key)\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel(\"cell area [pxl^2]\")\n",
    "plt.ylabel(\"cell edge length [pxl]\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
